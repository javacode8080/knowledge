> 最后更新：2025-12-18 | [返回主目录](../README.md)

| 序号 | 分类                | 核心内容概览                          | 
|------|---------------------|--------------------------------------|
| 01   | [Redis](redis/README.md) | Redis基础概念、数据类型、数据结构、持久化、消息传递、事件、高可用、高扩展、缓存文艺、性能调优等| 
| 02   | [MongoDB](mongodb/README.md) | NoSQL基本的概念以及MongoDB基础概念,MongoDB安装使用,MongoDB的原理和WiredTigger存储引擎,数据库核心知识点,数据模型设计,性能优化| 
| 03   | [ElasticSearch](elasticsearch/README.md) | ElasticSearch的概念基础,查询和聚合的基础使用,索引管理详解,查询详解，聚合详解，原理，优化，案例| 




# 一、扩展1：redis/mongoDB对于CAP理论关注的是AP(可用性+分区容错性)，不保证强一致性

## 1. Redis 为什么是最终一致性？如何保证？

### 为什么是最终一致性？
- **设计选择**：Redis 主要作为**内存数据库/缓存**使用，优先考虑**高性能**和**低延迟**。
- **复制机制**：默认采用**异步复制**（主从复制），主节点写入后立即返回，数据异步同步到从节点。
- **CAP 权衡**：在 CAP 理论中，Redis 通常优先选择 **AP**（可用性和分区容错性），牺牲强一致性。

### 如何保证最终一致性？
```plaintext
写入流程：
1. 客户端向主节点写入数据 → 主节点立即确认写入成功
2. 主节点异步将数据同步到从节点（可能有延迟）
3. 最终所有从节点都会收到更新

读取风险：
- 如果从从节点读取，可能读到旧数据
- 但最终（几毫秒到几秒内）所有节点数据会一致
```

**Redis 的一致性配置选项：**
- `WAIT` 命令：强制等待复制到指定数量的从节点（可实现强一致性）
- 同步复制：但会显著降低性能，很少使用
- 读写分离控制：可配置只从主节点读取保证强一致性

---

## 2. MongoDB 为什么是最终一致性？如何保证？

### 为什么是最终一致性？
- **分布式架构**：MongoDB 的副本集（Replica Set）默认使用**异步复制**。
- **性能优先**：为了高吞吐量，写操作默认只需主节点确认即可返回。
- **灵活配置**：提供多种一致性级别供选择，默认偏向最终一致性。

### 如何保证最终一致性？
```plaintext
副本集工作机制：
主节点（Primary） ← 异步复制 → 从节点（Secondaries）

写入过程：
1. 客户端写入主节点 → 立即确认
2. 主节点记录操作日志（oplog）
3. 从节点定期拉取oplog进行重放（通常有延迟）
```

**MongoDB 的一致性控制：**
```javascript
// 写关注（Write Concern） - 控制一致性强度
db.products.insert(
  { item: "card", qty: 15 },
  { writeConcern: { w: "majority", wtimeout: 5000 } }  // 强一致性：等待多数节点确认
)

// 读关注（Read Concern）
db.products.find().readConcern("majority")  // 只读取已提交到多数节点的数据
```

---

## 3. MySQL/PostgreSQL 是最终一致性吗？

### 传统认知 vs 实际状况

**单机部署：强一致性**
- MySQL/PostgreSQL 作为关系型数据库，**单机模式下严格遵循 ACID**，提供强一致性。
- 通过事务的隔离级别（如可串行化）保证数据一致性。

**分布式/复制场景：可配置的一致性**
```plaintext
MySQL主从复制：
主节点（Master） ← 异步复制 → 从节点（Slave）

默认情况：异步复制 → 最终一致性
可配置：半同步复制 → 强一致性（但性能下降）
```

### 具体对比

| 数据库 | 默认一致性 | 可达到的一致性 | 典型使用场景 |
|--------|------------|----------------|-------------|
| **Redis** | 最终一致性 | 可配置强一致性 | 缓存、会话存储、实时排行榜 |
| **MongoDB** | 最终一致性 | 可配置强一致性 | 文档存储、日志分析、内容管理 |
| **MySQL** | 单机强一致性<br>复制最终一致性 | 可配置强一致性 | 交易系统、财务数据 |
| **PostgreSQL** | 单机强一致性<br>复制最终一致性 | 可配置强一致性 | 复杂查询、GIS数据、分析系统 |

---

## 4. 为什么 NoSQL 数据库多选择最终一致性？

### 设计哲学差异
| 特性 | SQL数据库（MySQL/PostgreSQL） | NoSQL数据库（Redis/MongoDB） |
|------|-----------------------------|----------------------------|
| **核心目标** | 数据一致性、完整性 | 高性能、可扩展性 |
| **事务支持** | 完整ACID事务 | 有限事务或最终一致性 |
| **复制方式** | 同步/半同步优先 | 异步复制优先 |
| **适用场景** | 银行、电商交易等 | 社交网络、物联网、大数据分析 |

### 业务场景决定一致性选择
- **需要强一致性**：支付系统、库存管理（选用MySQL/PostgreSQL的强一致性模式）
- **可接受最终一致性**：用户点赞数、文章阅读量、缓存数据（选用Redis/MongoDB）

---

## 5. 如何在实际项目中选择？

### 强一致性场景（选用MySQL/PostgreSQL或配置NoSQL为强一致性）
```plaintext
- 金融交易：余额计算、转账操作
- 库存管理：商品库存扣减
- 票务系统：座位锁定
```

### 最终一致性可接受场景（选用Redis/MongoDB默认配置）
```plaintext
- 社交网络：点赞数、粉丝数统计
- 内容平台：文章阅读量、评论数
- 推荐系统：用户行为分析
- 缓存层：热点数据缓存
```

### 混合架构示例
```plaintext
现代互联网应用常用架构：
MySQL（强一致性） → 核心业务数据（用户账户、订单）
Redis（最终一致性） → 缓存、会话、计数器
MongoDB（最终一致性） → 日志、用户行为数据
```

---

## 总结

1. **Redis/MongoDB 是最终一致性**：这是它们的**默认设计选择**，旨在获得更好的性能和可扩展性。
2. **保证机制**：通过**异步复制**实现，系统保证在没有新写入时，数据最终会在所有节点一致。
3. **MySQL/PostgreSQL**：在单机模式下是强一致性，在分布式复制模式下默认也是最终一致性，但可以配置为强一致性。
4. **本质区别**：不是数据库类型决定的，而是**配置和业务需求**决定的。任何分布式数据库都可以在一致性和性能之间进行权衡。

**关键认知**：最终一致性不是"bug"，而是一种经过权衡的"feature"，在合适的业务场景下能提供更好的整体系统性能。

# 二、MySQL/PostgreSQL 在单机模式下是强一致性，但在集群/复制环境下默认并不是强一致性

## 为什么集群默认不是强一致性？

### 性能优先的设计选择
```plaintext
根本原因：在分布式系统的 CAP 理论权衡中，默认选择偏向【可用性(A)】和【性能】，而非强一致性(C)

同步复制 vs 异步复制的性能对比：
- 同步复制：写入延迟 = 网络往返时间 × 副本数量（性能差）
- 异步复制：写入延迟 ≈ 本地磁盘写入时间（性能好）
```

### 具体数据对比
| 复制模式 | 写入延迟 | 吞吐量 | 数据一致性 |
|---------|---------|--------|-----------|
| 异步复制 | 1-10ms | 高 | 最终一致性（默认） |
| 半同步复制 | 10-100ms | 中等 | 强一致性（可配置） |
| 全同步复制 | 100ms+ | 低 | 强一致性（很少用） |

---

## MySQL 如何保证集群下的强一致性？

### 1. 半同步复制（Semi-Synchronous Replication）
```sql
-- 在主节点上启用半同步复制
INSTALL PLUGIN rpl_semi_sync_master SONAME 'semisync_master.so';
SET GLOBAL rpl_semi_sync_master_enabled = 1;
SET GLOBAL rpl_semi_sync_master_timeout = 1000; -- 超时时间(ms)

-- 在从节点上启用
INSTALL PLUGIN rpl_semi_sync_slave SONAME 'semisync_slave.so';
SET GLOBAL rpl_semi_sync_slave_enabled = 1;
```

**工作机制：**
```plaintext
写入流程：
1. 事务在主节点提交
2. 主节点等待至少一个从节点确认收到binlog
3. 从节点确认后，主节点才向客户端返回成功
4. 保证数据至少存在于两个节点上
```

### 2. Group Replication（MySQL 5.7+） - 真正的强一致性
```sql
-- 配置Group Replication（基于Paxos协议）
SET GLOBAL group_replication_bootstrap_group=ON;
START GROUP_REPLICATION;
SET GLOBAL group_replication_bootstrap_group=OFF;
```

**强一致性保证机制：**
```plaintext
分布式事务提交过程：
1. 客户端向某个节点提交事务
2. 该节点将事务广播给组内所有节点
3. 多数节点(N/2+1)预提交成功后才真正提交
4. 采用Paxos协议保证所有节点数据一致
```

### 3. 读写分离控制
```sql
-- 确保从主节点读取（避免读到旧数据）
SET SESSION transaction_read_only = 0;

-- 或者使用Hint强制从主节点读取
SELECT /*+ SET_VAR(use_secondary_engine=OFF) */ * FROM table;
```

---

## PostgreSQL 如何保证集群下的强一致性？

### 1. 同步提交（Synchronous Commit）
```sql
-- 在postgresql.conf中配置
synchronous_commit = on        -- 全局开启同步提交
synchronous_standby_names = '*' -- 所有从节点都同步

-- 或者在事务级别控制
BEGIN;
SET LOCAL synchronous_commit = ON;
INSERT INTO table VALUES (...);
COMMIT;
```

**同步级别配置：**
```sql
-- 不同的同步强度
synchronous_commit = remote_apply    -- 最强：等待从节点应用完成
synchronous_commit = on              -- 强：等待从节点写入WAL
synchronous_commit = local           -- 弱：只等待本地写入
synchronous_commit = off             -- 最弱：异步复制
```

### 2. 使用同步复制插件的强一致性方案

#### 方案A：使用内置同步复制
```sql
-- 配置同步备节点
ALTER SYSTEM SET synchronous_standby_names = 'standby1,standby2';

-- 查看复制状态
SELECT application_name, sync_state FROM pg_stat_replication;
```

#### 方案B：使用第三方工具（如Patroni+etcd）
```yaml
# patroni.yml 配置
postgresql:
  parameters:
    synchronous_commit: "on"
    synchronous_standby_names: "*"
```

### 3. PostgreSQL 的物理复制 vs 逻辑复制

| 特性 | 物理复制（流复制） | 逻辑复制 |
|------|-------------------|----------|
| **一致性级别** | 块级别，强一致性可选 | 行级别，最终一致性 |
| **适用场景** | 高可用、灾难恢复 | 数据分发、跨版本复制 |
| **性能影响** | 较小 | 较大 |

---

## 实际配置示例：MySQL 强一致性集群

### MySQL Group Replication 完整配置
```ini
# my.cnf 配置
[mysqld]
# Group Replication 配置
plugin_load_add='group_replication.so'
group_replication_group_name="aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa"
group_replication_start_on_boot=off
group_replication_local_address= "node1:33061"
group_replication_group_seeds= "node1:33061,node2:33061,node3:33061"
group_replication_bootstrap_group=off

# 强一致性配置
transaction_write_set_extraction=XXHASH64
loose-group_replication_consistency= BEFORE_ON_PRIMARY_FAILOVER
```

### 验证强一致性
```sql
-- 在节点1写入
INSERT INTO account(balance) VALUES (1000);

-- 立即在节点2查询（应该立即看到最新数据）
SELECT * FROM account;  -- 强一致性保证这里能读到刚插入的数据
```

---

## PostgreSQL 强一致性验证

### 同步复制状态检查
```sql
-- 检查复制状态
SELECT 
    application_name,
    client_addr,
    state,
    sync_state,
    write_lag,
    flush_lag,
    replay_lag
FROM pg_stat_replication;

-- 测试强一致性
BEGIN;
-- 在主节点插入
INSERT INTO orders(user_id, amount) VALUES (1, 100.00);

-- 在提交前，在备节点查询（应该看不到）
-- 提交后，备节点立即可见（强一致性保证）
COMMIT;
```

---

## 为什么默认不启用强一致性？业务场景决定！

### 适合强一致性的场景
```plaintext
- 金融交易系统：余额计算、转账操作
- 库存管理系统：实时库存扣减
- 票务系统：座位锁定、票数控制
- 需要严格数据一致性的业务
```

### 适合最终一致性的场景
```plaintext
- 用户行为日志：点击量、浏览记录
- 社交网络：点赞数、评论数
- 内容平台：文章阅读量统计
- 缓存数据：热点数据缓存
```

### 性能代价对比
| 场景 | 异步复制 | 半同步复制 | 全同步复制 |
|------|---------|-----------|-----------|
| 写入延迟 | 1-5ms | 10-50ms | 50-200ms+ |
| 吞吐量 | 10000 TPS | 2000-5000 TPS | 500-1000 TPS |
| 数据安全 | 可能丢失最近数据 | 数据很安全 | 数据非常安全 |

---

## 总结

1. **默认选择性能**：MySQL/PostgreSQL 集群默认使用异步复制，是为了获得更好的性能表现。

2. **强一致性可配置**：两者都提供了强一致性选项：
   - **MySQL**：半同步复制、Group Replication
   - **PostgreSQL**：同步提交、同步备节点

3. **业务驱动选择**：是否启用强一致性取决于业务需求：
   - 对数据一致性要求极高的场景 → 启用强一致性（接受性能损失）
   - 对性能要求更高的场景 → 使用最终一致性（接受短暂数据不一致）

4. **现代趋势**：越来越多的系统采用**混合策略**，核心业务用强一致性，非核心业务用最终一致性。

**关键认知**：没有"最好"的一致性级别，只有"最适合"业务需求的一致性配置！

# 三、那为什么保证强一致性和可用性的时候，mysql/pg就不能保证分区容错了呢？
## 3.1、CAP定理的准确理解

首先明确CAP定理的精确定义：
- **C（一致性）**：所有节点看到的数据版本完全相同
- **A（可用性）**：每个请求都能获得响应（不保证是最新数据）
- **P（分区容错性）**：系统在网络分区时仍能继续运作

**关键洞察**：CAP不是平时"三选二"，而是在**网络分区发生时**必须"三选二"！

## 3.2、MySQL/PG的CA选择如何导致P缺失

### 场景还原：网络分区发生时
假设一个3节点的MySQL集群（半同步复制）：
```
节点A（主）---[网络分区]--- 节点B、C（从）
```

### 强一致性+可用性的困境：
```plaintext
写入请求到达节点A时：
选择1：等待节点B、C确认 → 保证一致性，但牺牲可用性（请求超时）
选择2：直接本地提交 → 保证可用性，但牺牲一致性（数据不一致）

MySQL/PG的设计选择：宁可不可用，也要保证一致性！
```

## 3.3、技术层面的具体冲突

### 冲突机制分析：
```plaintext
强一致性要求：写入必须同步到多数节点
可用性要求：每个请求必须立即响应
分区发生时：网络断开，无法联系多数节点

⇒ 系统陷入两难：
- 如果等待网络恢复：违反可用性（A）
- 如果继续服务：违反一致性（C）
- 唯一选择：停止服务，等待分区恢复
```

### MySQL Group Replication的实际行为：
```sql
-- 网络分区时，多数派节点继续服务，少数派节点自动只读
-- 如果无法形成多数派（如2/3节点失联），整个集群停止服务

SELECT * FROM performance_schema.replication_group_members;
-- 网络分区时显示：部分节点UNREACHABLE，集群可能进入只读模式
```

## 3.4、与AP型系统的对比

### NoSQL（如Cassandra、DynamoDB）的选择：
```plaintext
网络分区发生时：
- 允许所有节点继续读写
- 暂时接受数据不一致
- 网络恢复后自动解决冲突

⇒ 选择AP，牺牲强一致性
```

### 具体对比示例：
| 场景 | MySQL/PG（CA） | Cassandra（AP） |
|------|---------------|----------------|
| **3节点集群，1节点分区** | 2个节点形成多数派，继续服务 | 所有3个节点都继续读写 |
| **3节点集群，2节点分区** | 无法形成多数派，停止服务 | 所有节点继续读写，数据暂时不一致 |
| **恢复后的行为** | 数据始终保持一致 | 需要冲突解决，可能有数据合并 |

## 3.5、为什么这是必然的数学限制

### 用反证法思考：
假设存在一个系统能同时保证：
1. 强一致性（所有节点数据相同）
2. 高可用性（分区时仍能读写）
3. 分区容错性（分区不影响功能）

这违反了**分布式系统的基本通信原理**：网络分区意味着消息无法传递，而强一致性要求消息必须传递到所有节点。

### 形式化证明简版：
```
定义：
- N1, N2, N3 三个节点
- 客户端C写入数据D
- 网络分区：N1与{N2,N3}断开

如果保证强一致性：D必须同步到N2,N3才能返回成功
但网络分区：N1无法联系N2,N3
⇒ 矛盾！要么放弃一致性，要么放弃可用性
```

## 3.6、实际工程中的妥协方案

### MySQL/PG的"伪CA"真相：
```plaintext
现实中的MySQL/PG集群实际上是："在无分区时是CA，有分区时变成CP"

正常运行时：强一致性 + 高可用性
分区发生时：强一致性 + 不可用性
```

### 现代分布式数据库的演进：
**NewSQL数据库（如TiDB、CockroachDB）的尝试：**
- 采用更灵活的一致性模型（如线性一致性）
- 通过多副本和智能路由减少分区影响
- 但本质上仍受CAP定理约束

## 3.7、业务层面的实用建议

### 根据业务特征选择：
| 业务类型 | 推荐策略 | 理由 |
|---------|---------|------|
| **支付、金融核心** | MySQL强一致性 | 数据正确性优先 |
| **电商商品详情** | 最终一致性缓存 | 可用性优先，短暂不一致可接受 |
| **社交网络feed** | AP型数据库 | 高可用性最关键 |

### 混合架构设计：
```plaintext
现代互联网应用的典型架构：
核心交易系统：MySQL（CA倾向，分区时宁可不可用）
用户会话缓存：Redis（AP倾向，保证可用性）
大数据分析：ClickHouse（不同的一致性需求）
```

## 3.8、总结

MySQL和PostgreSQL在**设计哲学上优先保证数据正确性**，因此在网络分区发生时，它们选择：

**一致性(C) + 分区容错性(P) ⇒ 牺牲可用性(A)**

这不是技术缺陷，而是**经过深思熟虑的工程权衡**。这种选择特别适合金融、交易等对数据准确性要求极高的场景。

**关键认知**：CAP定理提醒我们，分布式系统没有"完美解决方案"，只有"最适合业务需求的权衡方案"。理解这些底层约束，才能做出更好的架构决策。